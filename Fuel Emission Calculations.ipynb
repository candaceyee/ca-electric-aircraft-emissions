{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.interpolate import lagrange, interp1d\n",
    "from pyproj import Transformer\n",
    "import re\n",
    "from leven import levenshtein\n",
    "from sklearn.cluster import dbscan\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from shapely import geometry\n",
    "import geopy.distance\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#webscraping packages\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#multiprocessing for faster webscraping\n",
    "from multiprocessing.dummy import Pool\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import difflib #for finding closest word match\n",
    "import os\n",
    "import ipdb as ipdb\n",
    "%pdb off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compiling all 2019 CA flights into one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only need to run section 1 once, as it saves the output into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(file_path):\n",
    "    #read in file and convert to dataframe\n",
    "    if file_path[-3:] == 'xls':\n",
    "        df = pd.read_html(file_path)[0]\n",
    "        df.columns = df.columns.droplevel(0) #drop Multiindex header\n",
    "        df = df[df.columns[:-1]] #drop last column\n",
    "        flight_data = df[['ActualAirborneTime', 'ActualBlockTime','Carrier', 'FlightNumber', 'TailNumber', 'Departure', 'Arrival', 'AircraftType', 'ScheduledDepartureDate', 'TaxiOutTime', 'TaxiInTime', 'ActualWheelsOff', 'ActualWheelsOn']]\n",
    "        return flight_data\n",
    "    elif file_path[-3:] == 'csv':\n",
    "        df = pd.read_csv(file_path, header = 1)\n",
    "        col_names = list(df)\n",
    "        col_names = [re.search('\\w+(?=\\\\xa0)', word).group(0) for word in col_names]\n",
    "        df.columns = col_names\n",
    "        flight_data = df[['ActualAirborneTime', 'ActualBlockTime','Carrier', 'FlightNumber', 'TailNumber', 'Departure', 'Arrival', 'AircraftType', 'ScheduledDepartureDate', 'TaxiOutTime', 'TaxiInTime', 'ActualWheelsOff', 'ActualWheelsOn']]\n",
    "        flight_data = flight_data.dropna()\n",
    "\n",
    "        for col in list(flight_data):\n",
    "            current_column = flight_data[col]\n",
    "            flight_data[col] = [re.search('.+(?=\\\\xa0)', value).group(0) for value in current_column]\n",
    "        return flight_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If compiling small airports, run section below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get folder of all airport-specific data directories\n",
    "folder_name = 'ASPM_Data_Small'\n",
    "directory_contents = os.listdir(folder_name)\n",
    "directory_contents.remove('.DS_Store')\n",
    "directory_contents.sort(key = str.upper)\n",
    "\n",
    "#list all file path names for future looping\n",
    "file_path_names = []\n",
    "for aa in directory_contents:\n",
    "    yy = os.listdir(folder_name + '/' + aa)\n",
    "    for kk in yy:\n",
    "        full_name = folder_name + '/' + aa + '/' + kk\n",
    "        file_path_names.append(full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Else if compiling the 5 large airports (LAX, SFO, OAK, SJC, SAN), change folder name accordingly and run section below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for larger airports, run this code\n",
    "folder_name = 'ASPM_Data_SAN'\n",
    "file_contents = os.listdir(folder_name)\n",
    "try:\n",
    "    file_contents.remove('.DS_Store')\n",
    "except:\n",
    "    pass\n",
    "file_contents.sort(key = str.upper)\n",
    "file_path_names = []\n",
    "for aa in file_contents:\n",
    "    yy = folder_name + '/' + aa\n",
    "    file_path_names.append(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#loop through all small airports to compile one dataframe of all flights\n",
    "print(datetime.now())\n",
    "flight_data_SAN = pd.DataFrame()\n",
    "for file in file_path_names:\n",
    "    print(file)\n",
    "    xx = prepare_dataframe(file)\n",
    "    flight_data_SAN = pd.concat([flight_data_SAN, xx], ignore_index = True).drop_duplicates()\n",
    "print(datetime.now())\n",
    "\n",
    "#save compiled flight data:\n",
    "#flight_data_SAN.to_csv('Save Points/1/flight_data_SAN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run code below to combine all airport flight data into one dataframe:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_airports_2019_df = pd.read_csv('Save Points/1/flight_data_small_airports.csv')\n",
    "LAX_2019_df = pd.read_csv('Save Points/1/flight_data_LAX.csv')\n",
    "SFO_2019_df = pd.read_csv('Save Points/1/flight_data_SFO.csv')\n",
    "SAN_2019_df = pd.read_csv('Save Points/1/flight_data_SAN.csv')\n",
    "SJC_2019_df = pd.read_csv('Save Points/1/flight_data_SJC.csv')\n",
    "OAK_2019_df = pd.read_csv('Save Points/1/flight_data_OAK.csv')\n",
    "\n",
    "all_CA_airports_2019_df = pd.concat([small_airports_2019_df, LAX_2019_df, SFO_2019_df, SAN_2019_df, \n",
    "                                     SJC_2019_df, OAK_2019_df], ignore_index = True).drop_duplicates()\n",
    "all_CA_airports_2019_df = all_CA_airports_2019_df.drop(all_CA_airports_2019_df.columns[[0]], axis = 1)\n",
    "#all_CA_airports_2019_df.to_csv('Save Points/1/all_CA_airports_2019.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Reading in Saved Flight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('airports.dat.txt', header = None)\n",
    "f = f.rename(columns = {0: 'ID', 1: 'Name', 2: 'City', 3: 'Country', 4: 'IATA', 5: 'ICAO', 6: 'Latitude', 7: 'Longitude',\n",
    "         8: 'Altitude', 9: 'Timezone', 10: 'DST', 11: 'Tz Database Timzone', 12: 'Type', 13: 'Source'})\n",
    "f = f[f['Country'] == 'United States']\n",
    "f = f[['IATA', 'ICAO', 'Latitude', 'Longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating two seperate dataframes: one df has intra-CA flights, the other OOC flights\n",
    "all_CA_flights_2019 = pd.read_csv('Save Points/1/all_CA_airports_2019.csv')\n",
    "#seperate international flights from domestic (we are only using domestic-CA flights)\n",
    "all_US_CA_flights_2019 = all_CA_flights_2019[(all_CA_flights_2019['Departure'].isin(f['IATA'])) & (all_CA_flights_2019['Arrival'].isin(f['IATA']))]\n",
    "ca_iata_codes = list(pd.read_csv('CA Geographical Data/CA_airports.csv')['AIRPORTID'])\n",
    "intra_CA = all_US_CA_flights_2019[all_US_CA_flights_2019.Departure.isin(ca_iata_codes)]\n",
    "intra_CA = intra_CA[intra_CA.Arrival.isin(ca_iata_codes)]\n",
    "out_of_CA = all_US_CA_flights_2019[~all_US_CA_flights_2019.index.isin(intra_CA.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Straight-Line Method for Determining Portion of Flight Within CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section needs to be run only once, as the emissions fractions are saved as a csv file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_lon_merge(airport_df, loc_df):\n",
    "    #merge on departures\n",
    "    dep_merge = airport_df.merge(loc_df, left_on = 'Departure', right_on = 'IATA', how = 'left')\n",
    "    dep_merge = dep_merge.drop(['IATA', 'ICAO'], axis = 1)\n",
    "    dep_merge = dep_merge.rename(columns = {'Latitude': 'Dep Lat', 'Longitude': 'Dep Lon'})\n",
    "\n",
    "    #merge on arrivals\n",
    "    arr_merge = dep_merge.merge(loc_df, left_on = 'Arrival', right_on = 'IATA', how = 'left')\n",
    "    arr_merge = arr_merge.drop(['IATA', 'ICAO'], axis = 1)\n",
    "    arr_merge = arr_merge.rename(columns = {'Latitude': 'Arr Lat', 'Longitude': 'Arr Lon'})\n",
    "    return arr_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data for CA vertices, define CA linear ring \n",
    "ca_vertices = pd.read_csv('CA Geographical Data/ca_vertices.csv').dropna()\n",
    "x_coords = ca_vertices['xcoord']\n",
    "y_coords = ca_vertices['ycoord']\n",
    "\n",
    "ca_shape_points = [geometry.Point(i) for i in list(zip(x_coords, y_coords))]\n",
    "ca_shape = geometry.polygon.LinearRing([[p.x, p.y] for p in ca_shape_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to create OD Pair Label\n",
    "def compare_od_pairs(row):\n",
    "    alph_od_pair = ''.join(sorted([row[5], row[6]]))\n",
    "    return alph_od_pair\n",
    "\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "#define function to convert lat/lon coordinates to x,y coordinates\n",
    "def convert_to_xy(lon, lat):\n",
    "    inProj  = Proj(\"+init=EPSG:4326\")\n",
    "    outProj = Proj(\"+init=EPSG:3857\")\n",
    "    return transform(inProj, outProj, lon, lat)\n",
    "\n",
    "ca_iata_codes = list(pd.read_csv('CA Geographical Data/CA_airports.csv')['AIRPORTID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with_locations = lat_lon_merge(out_of_CA, f)\n",
    "insert = with_locations.apply(compare_od_pairs, axis = 1)\n",
    "with_locations.insert(0, 'OD Pair Name', insert)\n",
    "unique_OD = list(np.unique(np.array(with_locations['OD Pair Name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this cell takes ~30-40 minutes to run; do not run if already run once (output saves to CSV below)\n",
    "emissions_frac_within_CA = {}\n",
    "for od_idx in unique_OD:\n",
    "    first_airport = od_idx[0:3]\n",
    "    second_airport = od_idx[3:6]\n",
    "    f_lon, f_lat = f[f['IATA'] == first_airport]['Longitude'].values[0], f[f['IATA'] == first_airport]['Latitude'].values[0]\n",
    "    s_lon, s_lat = f[f['IATA'] == second_airport]['Longitude'].values[0], f[f['IATA'] == second_airport]['Latitude'].values[0]\n",
    "    f_pt = list(convert_to_xy(f_lon, f_lat))\n",
    "    s_pt = list(convert_to_xy(s_lon, s_lat))\n",
    "    travel_line = geometry.LineString([f_pt, s_pt])\n",
    "    if travel_line.intersects(ca_shape):\n",
    "        intersection = travel_line.intersection(ca_shape)\n",
    "        if type(intersection) == geometry.multipoint.MultiPoint:\n",
    "            intersection = intersection[0]\n",
    "        if first_airport in ca_iata_codes:\n",
    "            frac_within_ca = geometry.LineString([f_pt, intersection]).length / travel_line.length\n",
    "        else:\n",
    "            frac_within_ca = geometry.LineString([s_pt, intersection]).length / travel_line.length\n",
    "        emissions_frac_within_CA[od_idx] = frac_within_ca\n",
    "    else:\n",
    "        emissions_frac_within_CA[od_idx] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_in_CA_df = pd.DataFrame.from_dict(emissions_frac_within_CA, orient = 'index').rename(columns = {0:'Frac in CA'})\n",
    "frac_in_CA_df.to_csv('Save Points/2/frac_in_CA.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5*1.5, 9*1.5))\n",
    "x,y = ca_shape.xy\n",
    "plt.plot(x, y, color = '#3c9efa')\n",
    "plt.plot(*travel_line.xy, color= '#fca903')\n",
    "plt.scatter(*intersection.xy, color = '#f74134', s = 100)\n",
    "plt.scatter(*dep_point, color = '#f74134', s = 100)\n",
    "plt.scatter(*arr_point, color = '#f74134', s = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Appending OOC Emission Fractions and OD Pair Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def od_pair_name_addition(df):\n",
    "    a = df[['Departure', 'Arrival']].values\n",
    "    a = np.sort(a)\n",
    "    a_df = pd.DataFrame(a)\n",
    "    a_df = pd.Series(a_df[0] + a_df[1])\n",
    "    insert = pd.concat([a_df, pd.Series(df.index)], axis = 1).set_index(1)\n",
    "    df_return = pd.concat([insert, df], axis = 1).rename(columns = {0: 'OD Pair Name'})\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds OD pair name for identification to each dataframe\n",
    "intra_CA = od_pair_name_addition(intra_CA)\n",
    "out_of_CA = od_pair_name_addition(out_of_CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_in_CA_df = pd.read_csv('Save Points/2/frac_in_CA.csv')\n",
    "frac_in_CA_df = frac_in_CA_df.rename(columns = {'Unnamed: 0': 'OD Pair Name'})\n",
    "out_of_CA = frac_in_CA_df.merge(out_of_CA, on = 'OD Pair Name', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using European Environmental Agency (EEA) Aviation Master Emissions Calculator to calculate CCD (Cruise/Climb/Descent) Fuel Flow and Emissions Indices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be found at: https://www.eea.europa.eu/publications/emep-eea-guidebook-2019/part-b-sectoral-guidance-chapters/1-energy/1-a-combustion/1-a-3-a-aviation-1/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following lines of code need only be run once (saves to csv below):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_lon_merge(airport_df, loc_df):\n",
    "    #merge on departures\n",
    "    dep_merge = airport_df.merge(loc_df, left_on = 'Departure', right_on = 'IATA', how = 'left')\n",
    "    dep_merge = dep_merge.drop(['IATA', 'ICAO'], axis = 1)\n",
    "    dep_merge = dep_merge.rename(columns = {'Latitude': 'Dep Lat', 'Longitude': 'Dep Lon'})\n",
    "\n",
    "    #merge on arrivals\n",
    "    arr_merge = dep_merge.merge(loc_df, left_on = 'Arrival', right_on = 'IATA', how = 'left')\n",
    "    arr_merge = arr_merge.drop(['IATA', 'ICAO'], axis = 1)\n",
    "    arr_merge = arr_merge.rename(columns = {'Latitude': 'Arr Lat', 'Longitude': 'Arr Lon'})\n",
    "    return arr_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#following four lines gets rid of flights in which A/C Type is not given:\n",
    "intra_CA = intra_CA[~intra_CA['AircraftType'].isnull()]\n",
    "out_of_CA = out_of_CA[~out_of_CA['AircraftType'].isnull()]\n",
    "\n",
    "intra_CA = intra_CA[~(intra_CA['AircraftType'] == '-1')]\n",
    "out_of_CA = out_of_CA[~(out_of_CA['AircraftType'] == '-1')]\n",
    "\n",
    "orig_len_intra = len(intra_CA); orig_len_ooc = len(out_of_CA)\n",
    "\n",
    "intra_CA_w_loc = lat_lon_merge(intra_CA, f)\n",
    "out_of_CA_w_loc = lat_lon_merge(out_of_CA, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate distance of each flight (in Nautical-Miles (NM))\n",
    "from pyproj import Geod\n",
    "\n",
    "wgs84_geod = Geod(ellps='WGS84') #Distance will be measured on this ellipsoid - more accurate than a spherical method\n",
    "\n",
    "#Get distance between pairs of lat-lon points\n",
    "def Distance(lat1,lon1,lat2,lon2):\n",
    "    az12, az21,dist = wgs84_geod.inv(lon1,lat1,lon2,lat2) #Yes, this order is correct\n",
    "    return dist\n",
    "\n",
    "distances_i = Distance(intra_CA_w_loc['Dep Lat'].tolist(), intra_CA_w_loc['Dep Lon'].tolist(), intra_CA_w_loc['Arr Lat'].tolist(), intra_CA_w_loc['Arr Lon'].tolist())\n",
    "distances_o = Distance(out_of_CA_w_loc['Dep Lat'].tolist(), out_of_CA_w_loc['Dep Lon'].tolist(), out_of_CA_w_loc['Arr Lat'].tolist(), out_of_CA_w_loc['Arr Lon'].tolist())\n",
    "\n",
    "distances_i_nm = np.array(distances_i) / 1852\n",
    "distances_o_nm = np.array(distances_o) / 1852\n",
    "\n",
    "intra_CA['Distance (NM)'] = distances_i_nm\n",
    "out_of_CA['Distance (NM)'] = distances_o_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in EI/FF data and clean dataframe for calculations\n",
    "aircraft_master_CCD_emissions = pd.read_csv('aircraft_master_CCD_emissions.csv')\n",
    "aircraft_master_CCD_emissions = aircraft_master_CCD_emissions[aircraft_master_CCD_emissions['LTO or CCD'] == 'CCD']\n",
    "\n",
    "aircraft_master_CCD_emissions = aircraft_master_CCD_emissions[['IMPACT ACFT ID', '\\xa0DURATION', \n",
    "                                                               '\\xa0DISTANCE NM', '\\xa0FUEL BURNT KG', \n",
    "                                                               'CO2 (3,15 or 3,05)\\xa0', '\\xa0NOX', \n",
    "                                                               '\\xa0CO', '\\xa0HC', '\\xa0PM TOTAL']]\n",
    "col_names = list(aircraft_master_CCD_emissions)\n",
    "col_names_new = [re.sub(\"[\\xa0]\", \"\", cc) for cc in col_names]\n",
    "aircraft_master_CCD_emissions.columns = col_names_new\n",
    "aircraft_master_CCD_emissions = aircraft_master_CCD_emissions.replace({\"\\\\xa0\": \"\", \" \": \"\"}, regex = True)\n",
    "aircraft_master_CCD_emissions = aircraft_master_CCD_emissions.astype({'DISTANCE NM': 'float64', 'FUEL BURNT KG': 'float64',\n",
    "                                                                      'CO2 (3,15 or 3,05)': 'float64', 'NOX': 'float64',\n",
    "                                                                      'CO': 'float64', 'HC': 'float64', 'PM TOTAL': 'float64'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate emissions indices for each pollutant\n",
    "fuel_consumed_raw = aircraft_master_CCD_emissions['FUEL BURNT KG']\n",
    "CO2_cr_ei = aircraft_master_CCD_emissions['CO2 (3,15 or 3,05)'] / fuel_consumed_raw #leave in kg\n",
    "NOx_cr_ei = aircraft_master_CCD_emissions['NOX'] * 1000 / fuel_consumed_raw #convert rest to grams\n",
    "CO_cr_ei = aircraft_master_CCD_emissions['CO'] * 1000 / fuel_consumed_raw\n",
    "HC_cr_ei = aircraft_master_CCD_emissions['HC'] * 1000 / fuel_consumed_raw\n",
    "PM_cr_ei = aircraft_master_CCD_emissions['PM TOTAL'] * 1000 / fuel_consumed_raw #kg/kg --> g/kg\n",
    "\n",
    "#calculate fuel flow for cruising (alt. version of ff with pressure/temp coeff)\n",
    "duration_sec = [sum(x * int(t) for x, t in zip([1, 60, 3600], reversed(tt.split(\":\")))) for tt in list(aircraft_master_CCD_emissions['DURATION'])]\n",
    "ff_cr_alt = fuel_consumed_raw / duration_sec  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe with EI and FF values calculated above\n",
    "ac_cruise_ff_ei = pd.DataFrame()\n",
    "ac_cruise_ff_ei['AircraftType'] = aircraft_master_CCD_emissions['IMPACT ACFT ID']\n",
    "ac_cruise_ff_ei['Distance (NM)'] = aircraft_master_CCD_emissions['DISTANCE NM']\n",
    "ac_cruise_ff_ei['Fuel Flow CCD (kg/sec)'] = ff_cr_alt\n",
    "ac_cruise_ff_ei['HC EI CCD (g/kg)'] = HC_cr_ei\n",
    "ac_cruise_ff_ei['CO EI CCD (g/kg)'] = CO_cr_ei\n",
    "ac_cruise_ff_ei['NOx EI CCD (g/kg)'] = NOx_cr_ei\n",
    "ac_cruise_ff_ei['PM EI CCD (g/kg)'] = PM_cr_ei\n",
    "ac_cruise_ff_ei['CO2 EI CCD (kg/kg)'] = CO2_cr_ei\n",
    "ac_cruise_ff_ei.to_csv('ac_cruise_ff_ei.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each unique aircraft type: create interpolation functions that relate distance of flight to FF and EI\n",
    "ac_unique = list(ac_cruise_ff_ei.AircraftType.unique())\n",
    "ff_interp = {}; hc_ei_interp = {}; co_ei_interp = {}; nox_ei_interp = {}; pm_ei_interp = {}; co2_ei_interp = {}\n",
    "for ac in ac_unique:\n",
    "    unique_ac_df = ac_cruise_ff_ei[ac_cruise_ff_ei['AircraftType'] == ac]\n",
    "    x = unique_ac_df['Distance (NM)']\n",
    "    ff_interp[ac] = interp1d(x, unique_ac_df['Fuel Flow CCD (kg/sec)'], fill_value = 'extrapolate')\n",
    "    hc_ei_interp[ac] = interp1d(x, unique_ac_df['HC EI CCD (g/kg)'], fill_value = 'extrapolate')\n",
    "    co_ei_interp[ac] = interp1d(x, unique_ac_df['CO EI CCD (g/kg)'], fill_value = 'extrapolate')\n",
    "    nox_ei_interp[ac] = interp1d(x, unique_ac_df['NOx EI CCD (g/kg)'], fill_value = 'extrapolate')\n",
    "    pm_ei_interp[ac] = interp1d(x, unique_ac_df['PM EI CCD (g/kg)'],fill_value = 'extrapolate')\n",
    "    co2_ei_interp[ac] = interp1d(x, unique_ac_df['CO2 EI CCD (kg/kg)'], fill_value = 'extrapolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(ac_cruise_ff_ei['AircraftType'].unique())\n",
    "set2 = set(all_US_CA_flights_2019.AircraftType.unique())\n",
    "missing_ac = set2 - set1\n",
    "not_missing_ac = set1.intersection(set2)\n",
    "all_ac_data_provided = list(ac_cruise_ff_ei.AircraftType.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "missing_ac_df = all_US_CA_flights_2019[all_US_CA_flights_2019['AircraftType'].isin(missing_ac)]\n",
    "#missing_ac_df.groupby('AircraftType').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_ac_dict = {'A20N': 'A320', 'A21N': 'A321', 'A330': 'A333', 'A359': 'A380', 'A388': 'A380', 'ASTR': 'G150', \n",
    "               'AT43': 'ATR42', 'AT45': 'ATR42', 'AT72': 'ATR72', 'B190': 'BE90', 'B350': 'BE300', 'B38M': 'B737', \n",
    "               'B39M': 'B737', 'B712': 'MD90', 'B757': 'B573', 'B767': 'B764', 'B77L': 'B772', 'B777': 'B773', \n",
    "               'B78X': 'B788', 'BE20': 'BE200', 'BE30': 'BE300', 'BE40': 'BE400', 'BE9L': 'BE90', 'BE9T': 'BE90',\n",
    "               'C25A': 'C525', 'C25B': 'C525', 'C25C': 'C525', 'C25M': 'C525', 'C56X': 'C560', 'C68A': 'C680', \n",
    "               'C68L': 'C680', 'CL30': 'CL300', 'CL35': 'CL300', 'CL60': 'CL600', 'CRJ1': 'CL600RJ',\n",
    "               'CRJ2': 'CL600RJ', 'CRJ7': 'CL700RJ', 'CRJ9': 'CL900RJ', 'DH8': 'DHC8', 'DH8A': 'DHC8',\n",
    "               'DH8B': 'DHC8', 'DH8C': 'DHC8', 'DH8D': 'DHC8', 'E35L': 'EMB600', 'E45X': 'E145', 'E50P': 'EMB100',\n",
    "               'E545': 'E500', 'E545': 'E500', 'E55P': 'EMB300', 'E75L': 'E175', 'E75S': 'E175', 'F2TH': 'FA2000',\n",
    "               'F900': 'FA900', 'GA5C': 'GA7', 'GA6C': 'GA7', 'GALX': 'G200', 'GL5T': 'BD700', 'GLEX': 'BD700',\n",
    "               'GLF4': 'G400', 'GLF5': 'G500', 'GLF6': 'G650', 'H25A': 'BAE125', 'H25B': 'BAE125', \n",
    "               'H25C': 'BAE125', 'MD83': 'MD80', 'MD87': 'MD80', 'MD88': 'MD80', 'SW4': 'SA226'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing AircraftType with equivalent or approximations as given in alt_ac_dict\n",
    "intra_mapping = intra_CA['AircraftType'].map(alt_ac_dict, na_action = 'ignore').dropna()\n",
    "ooc_mapping = out_of_CA['AircraftType'].map(alt_ac_dict, na_action = 'ignore').dropna()\n",
    "\n",
    "intra_CA.loc[intra_mapping.index, 'AircraftType'] = intra_mapping\n",
    "out_of_CA.loc[ooc_mapping.index, 'AircraftType'] = ooc_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_CA = intra_CA[intra_CA['AircraftType'].isin(all_ac_data_provided)]\n",
    "out_of_CA = out_of_CA[out_of_CA['AircraftType'].isin(all_ac_data_provided)]\n",
    "\n",
    "loss_ac_type_intra = (orig_len_intra - len(intra_CA)) / orig_len_intra\n",
    "loss_ac_type_ooc = (orig_len_ooc - len(out_of_CA)) / orig_len_ooc\n",
    "print('Loss due to missing A/C Type (Intra-CA): {}%'.format(round(loss_ac_type_intra * 100, 2)))\n",
    "print('Loss due to missing A/C Type (OOC): {}%'.format(round(loss_ac_type_ooc * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ff_ei_ccd(df):\n",
    "    print(datetime.now())\n",
    "    df['Fuel Flow CCD (kg/sec)'] = df.apply(lambda x: ff_interp[x['AircraftType']](x['Distance (NM)']), axis = 1)\n",
    "    print(datetime.now())\n",
    "    df['HC EI CCD (g/kg)'] = df.apply(lambda x: hc_ei_interp[x['AircraftType']](x['Distance (NM)']), axis = 1)\n",
    "    df['CO EI CCD (g/kg)'] = df.apply(lambda x: co_ei_interp[x['AircraftType']](x['Distance (NM)']), axis = 1)\n",
    "    df['NOx EI CCD (g/kg)'] = df.apply(lambda x: nox_ei_interp[x['AircraftType']](x['Distance (NM)']), axis = 1)\n",
    "    df['PM EI CCD (g/kg)'] = df.apply(lambda x: pm_ei_interp[x['AircraftType']](x['Distance (NM)']), axis = 1)\n",
    "    df['CO2 EI CCD (kg/kg)'] = df.apply(lambda x: co2_ei_interp[x['AircraftType']](x['Distance (NM)']), axis = 1)\n",
    "    print(datetime.now())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_CA = calculate_ff_ei_ccd(intra_CA)\n",
    "out_of_CA = calculate_ff_ei_ccd(out_of_CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_CA.to_csv('Save Points/3/intra_CA_CCD.csv', index = False)\n",
    "out_of_CA.to_csv('Save Points/3/out_of_CA_CCD.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preparing N-Number and LTO FF/EI Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in entire database of aircraft N-Number and Engine Mfr Code\n",
    "aircraft_data_master = pd.read_csv('ReleasableAircraft/MASTER.txt')[['N-NUMBER', 'ENG MFR MDL']]\n",
    "aircraft_data_master = aircraft_data_master[aircraft_data_master['ENG MFR MDL'] != '     ']\n",
    "aircraft_data_master['ENG MFR MDL'] = aircraft_data_master['ENG MFR MDL'].astype(int)\n",
    "\n",
    "#reading in Engine database (Engine Mfr Code and Model Name)\n",
    "aircraft_data_engine = pd.read_csv('ReleasableAircraft/ENGINE.txt')[['CODE', 'MODEL']]\n",
    "aircraft_data_engine = aircraft_data_engine.rename(columns = {'CODE': 'ENG MFR MDL'})\n",
    "\n",
    "#merge two databases ==> relates N-Number (tail number) of aircraft to Model Name to find fuel flow later\n",
    "aircraft_model_names = aircraft_data_master.merge(aircraft_data_engine, on = 'ENG MFR MDL', how = 'left')\n",
    "aircraft_model_names['N-NUMBER'] = 'N' + aircraft_model_names['N-NUMBER'].astype(str)\n",
    "aircraft_model_names = aircraft_model_names.rename(columns = {'N-NUMBER': 'TailNumber'})\n",
    "aircraft_model_names = aircraft_model_names.set_index('TailNumber')\n",
    "aircraft_model_names.index = [index.strip() for index in aircraft_model_names.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for guest lecture:\n",
    "#aircraft_model_names.to_csv('ReleasableAircraft/nn_em.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in fuel flow and emissions index data\n",
    "fuel_flow_emissions = pd.read_excel('Emissions Data/emissions_indices.xlsx').rename(columns = {'Engine Identification': 'MODEL'})\n",
    "fuel_flow_emissions = fuel_flow_emissions[['MODEL', 'Fuel Flow T/O (kg/sec)', 'Fuel Flow C/O (kg/sec)', 'Fuel Flow App (kg/sec)', 'Fuel Flow Idle (kg/sec)',\n",
    "                                           'HC EI T/O (g/kg)', 'HC EI C/O (g/kg)', 'HC EI App (g/kg)', 'HC EI Idle (g/kg)',\n",
    "                                           'CO EI T/O (g/kg)', 'CO EI C/O (g/kg)', 'CO EI App (g/kg)', 'CO EI Idle (g/kg)',\n",
    "                                           'NOx EI T/O (g/kg)', 'NOx EI C/O (g/kg)', 'NOx EI App (g/kg)', 'NOx EI Idle (g/kg)', \n",
    "                                           'SN T/O', 'SN C/O', 'SN App', 'SN Idle']]\n",
    "fuel_flow_emissions = fuel_flow_emissions.dropna()\n",
    "fuel_flow_emissions = fuel_flow_emissions.groupby('MODEL', as_index=False).mean()\n",
    "fuel_flow_emissions = fuel_flow_emissions.set_index('MODEL')\n",
    "fuel_flow_emissions = fuel_flow_emissions.rename(columns={'SN T/O': 'SN EI T/O', 'SN C/O': 'SN EI C/O', 'SN App': 'SN EI App', 'SN Idle': 'SN EI Idle'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Calculating Fuel Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_CA = pd.read_csv('Save Points/3/intra_CA_CCD.csv')\n",
    "out_of_CA = pd.read_csv('Save Points/3/out_of_CA_CCD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_airport_codes = pd.read_csv('CA Geographical Data/CA_airports.csv')['AIRPORTID']\n",
    "out_of_CA['From CA'] = out_of_CA['Departure'].isin(ca_airport_codes).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "unique_aircrafts = np.unique(list(out_of_CA['AircraftType']) +  list(intra_CA['AircraftType']))\n",
    "print(len(unique_aircrafts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_engines_dict = {'A306': 2, 'A319': 2, 'A310': 2, 'A320': 2, 'A332': 2, 'A333': 2, 'A343': 4, 'A346': 4,\n",
    "                   'A321': 2, 'A380': 4, 'AN12': 4, 'ATR42': 2, 'ATR72': 2, 'B722': 3, 'B733': 2,\n",
    "                   'B734': 2, 'B732': 2, 'B735': 2, 'B737': 2, 'B738': 2, 'B739': 2, 'B744': 4, 'B748': 4, \n",
    "                   'B752': 2, 'B753': 2, 'B762': 2, 'B763': 2, 'B764': 2, 'B772': 2, 'B773': 2, 'B77W': 2, \n",
    "                   'B788': 2, 'B789': 2, 'BAE125': 2, 'BD700': 2, 'BE200': 2, 'BE300': 2, 'BE400': 2, 'BE55': 2, \n",
    "                   'BE58': 2, 'BE90': 2, 'BE99': 2, 'C208': 1, 'C340': 2, 'C402': 2, 'C414': 2, 'C421': 2,\n",
    "                   'C425': 2, 'C501': 2, 'C510': 2, 'C525': 2, 'C550': 2, 'C551': 2, 'C560': 2, 'C650': 2, \n",
    "                   'C680': 2, 'C750': 2, 'CL300': 2, 'CL600': 2, 'CL600RJ': 2, 'CL700RJ': 2, 'CL900RJ': 2,\n",
    "                   'DC10': 3, 'DHC6': 2, 'DHC8': 2, 'E120': 2, 'E135': 2, 'E145': 2, 'E170': 2, 'E175': 2, \n",
    "                   'E500': 1, 'EMB100': 2, 'EMB300': 2, 'EMB600': 2, 'FA10': 2, 'FA20': 2, 'FA2000': 2, \n",
    "                   'FA50': 3, 'FA7X': 3, 'FA900': 3, 'G150': 2, 'G200': 1, 'G280': 2, 'G400': 2, 'G500': 2, \n",
    "                   'G650': 2, 'GA7': 2, 'LJ31': 2, 'LJ35': 2, 'LJ40': 2, 'LJ45': 2, 'LJ55': 2, 'LJ60': 2, \n",
    "                   'LJ75': 2, 'MD11': 3, 'MD80': 2, 'MD90': 2, 'PA31': 2, 'PC12': 1, 'PRM1': 2, 'SA226': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_CA['No. Engines'] = intra_CA['AircraftType'].map(no_engines_dict)\n",
    "out_of_CA['No. Engines'] = out_of_CA['AircraftType'].map(no_engines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather \n",
    "\n",
    "#Los Angeles County:\n",
    "wi_l_la = np.mean([51, 51, 51])\n",
    "wi_h_la = np.mean([67, 67, 67])\n",
    "sp_l_la = np.mean([51, 53, 56])\n",
    "sp_h_la = np.mean([67, 69, 70])\n",
    "su_l_la = np.mean([58, 62, 62])\n",
    "su_h_la = np.mean([73, 77, 79])\n",
    "fa_l_la = np.mean([62, 59, 55])\n",
    "fa_h_la = np.mean([78, 75, 71])\n",
    "\n",
    "#Sacremento:\n",
    "wi_l_sa = np.mean([38, 39, 41])\n",
    "wi_h_sa = np.mean([54, 48, 60])\n",
    "sp_l_sa = np.mean([44, 46, 51])\n",
    "sp_h_sa = np.mean([65, 71, 80])\n",
    "su_l_sa = np.mean([56, 58, 58])\n",
    "su_h_sa = np.mean([87, 92, 91])\n",
    "fa_l_sa = np.mean([56, 50, 43])\n",
    "fa_h_sa = np.mean([87, 78, 64])\n",
    "\n",
    "#Eureka:\n",
    "wi_l_eu = np.mean([41, 41, 42])\n",
    "wi_h_eu = np.mean([55, 56, 56])\n",
    "sp_l_eu = np.mean([43, 44, 47])\n",
    "sp_h_eu = np.mean([57, 58, 60])\n",
    "su_l_eu = np.mean([50, 52, 53])\n",
    "su_h_eu = np.mean([62, 53, 64])\n",
    "fa_l_eu = np.mean([50, 47, 44])\n",
    "fa_h_eu = np.mean([64, 62, 58])\n",
    "\n",
    "#San Diego:\n",
    "wi_l_sd = np.mean([49, 48, 65])\n",
    "wi_h_sd = np.mean([65, 65, 76])\n",
    "sp_l_sd = np.mean([61, 54, 67])\n",
    "sp_h_sd = np.mean([73, 69, 76])\n",
    "su_l_sd = np.mean([65, 62, 59])\n",
    "su_h_sd = np.mean([75, 71, 69])\n",
    "fa_l_sd = np.mean([56, 53, 51])\n",
    "fa_h_sd = np.mean([67, 66, 65])\n",
    "\n",
    "#San Francisco County:\n",
    "wi_l_sf = np.mean([46, 53, 54])\n",
    "wi_h_sf = np.mean([57, 66, 67])\n",
    "sp_l_sf = np.mean([51, 49, 49])\n",
    "sp_h_sf = np.mean([64, 63, 62])\n",
    "su_l_sf = np.mean([47, 46, 55])\n",
    "su_h_sf = np.mean([60, 57, 68])\n",
    "fa_l_sf = np.mean([55, 54, 50])\n",
    "fa_h_sf = np.mean([70, 69, 63])\n",
    "\n",
    "#Fresno:\n",
    "wi_l_fr = np.mean([38, 38, 42])\n",
    "wi_h_fr = np.mean([56, 56, 63])\n",
    "sp_l_fr = np.mean([45, 49, 55])\n",
    "sp_h_fr = np.mean([68, 75, 84])\n",
    "su_l_fr = np.mean([61, 66, 65])\n",
    "su_h_fr = np.mean([92, 96, 96])\n",
    "fa_l_fr = np.mean([61, 53, 43])\n",
    "fa_h_fr = np.mean([91, 80, 66])\n",
    "\n",
    "wi_l = (wi_l_la + wi_l_sa + wi_l_eu + wi_l_sd + wi_l_sf + wi_l_fr) / 6\n",
    "wi_h = (wi_h_la + wi_h_sa + wi_h_eu + wi_h_sd + wi_h_sf + wi_h_fr) / 6\n",
    "sp_l = (sp_l_la + sp_l_sa + sp_l_eu + sp_l_sd + sp_l_sf + sp_l_fr) / 6\n",
    "sp_h = (sp_h_la + sp_h_sa + sp_h_eu + sp_h_sd + sp_h_sf + sp_h_fr) / 6\n",
    "su_l = (su_l_la + su_l_sa + su_l_eu + su_l_sd + su_l_sf + su_l_fr) / 6\n",
    "su_h = (su_h_la + su_h_sa + su_h_eu + su_h_sd + su_h_sf + su_h_fr) / 6\n",
    "fa_l = (fa_l_la + fa_l_sa + fa_l_eu + fa_l_sd + fa_l_sf + fa_l_fr) / 6\n",
    "fa_h = (fa_h_la + fa_h_sa + fa_h_eu + fa_h_sd + fa_h_sf + fa_h_fr) / 6 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Guest Lecture!\n",
    "\n",
    "weather_df = pd.DataFrame()\n",
    "weather_df['Low'] = [wi_l, sp_l, su_l, fa_l]\n",
    "weather_df['High'] = [wi_h, sp_h, su_h, fa_h]\n",
    "weather_df['Season'] = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "weather_df = weather_df.set_index('Season')\n",
    "weather_df.to_csv('Guest Lecture/weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from: https://stackoverflow.com/questions/11384714/ignore-case-with-difflib-get-close-matches\n",
    "def get_close_matches_icase(word, possibilities, *args, **kwargs):\n",
    "    \"\"\" Case-insensitive version of difflib.get_close_matches \"\"\"\n",
    "    lword = word.lower()\n",
    "    lpos = {}\n",
    "    for p in possibilities:\n",
    "        if p.lower() not in lpos:\n",
    "            lpos[p.lower()] = [p]\n",
    "        else:\n",
    "            lpos[p.lower()].append(p)\n",
    "    lmatches = difflib.get_close_matches(lword, lpos.keys(), *args, **kwargs)\n",
    "    ret = [lpos[m] for m in lmatches]\n",
    "    ret = itertools.chain.from_iterable(ret)\n",
    "    return set(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hand-created dictionary of engine approximations based on aircraft types, based on ICAO's 2021\n",
    "#Aricraft Emissions Databank\n",
    "engine_approx = {'A306': 'CF6 SERIES', 'A310': 'CF6 SERIES', 'A319': 'CFM56 SERIES', 'A320':'CFM56-5B4/P', \n",
    "                 'A321': 'V2533-A5', 'A332': 'CF6-80E1 SERIES', 'A333':'CF6-80E1 SERIES', 'A343': 'CFM56-5C4/P',\n",
    "                 'A346': 'Trent 556', 'A380':'Trent 970 SERIES', 'A388': 'Trent 970', 'ATR72': 'PW100 SERIES',\n",
    "                 'B722': 'JT8D-11', 'B732': 'JT8D-15 SERIES', 'B733': 'CFM56-3B SERIES', 'B734': 'CFM56-3C SERIES',\n",
    "                 'B735': 'CFM56-3B SERIES', 'B736': 'CFM56-7B20', 'B737': 'CFM56-7B SERIES', \n",
    "                 'B738': 'CFM56-7B SERIES', 'B739': 'CFM56-7B SERIES', 'B744': 'RB211-524H', 'B748': 'GEnx-2B67', \n",
    "                 'B752': 'RB211-535E4', 'B753': 'PW2037', 'B762': 'PW4062', 'B763': 'PW4062', 'B764': 'PW4062',\n",
    "                 'B772': 'GE90-94B', 'B773': 'PW4098', 'B77W': 'GE90-115B', 'B788': 'GEnx-1B SERIES', \n",
    "                 'B789':'GEnx-1B SERIES', 'BAE125': 'TFE731-3', 'BD700':'BR700-710 SERIES', \n",
    "                 'BE400': 'JT15D-5 SERIES', 'C501': 'JT15D-1 series', 'C550': 'JT15D-4 series', \n",
    "                 'C650': 'TFE731-3', 'C680': 'PW306A', 'C750': 'AE3007C1', 'CL300': 'HTF7000 SERIES', \n",
    "                 'CL600': 'CF34-3A SERIES', 'CL600RJ': 'CF34-3B SERIES', 'CL700RJ': 'CF34-8C SERIES', \n",
    "                 'CL900RJ': 'CF34-8C5 SERIES', 'CRJ9': 'CF34-8C5', 'DC10': 'CF6-6D SERIES', \n",
    "                 'E135': 'AE3007A3', 'E145': 'AE3007A SERIES', 'E170': 'CF34-8E SERIES', \n",
    "                 'E190': 'CF34-10E SERIES', 'FA10': 'TFE731-2-2B SERIES', 'FA50': 'TFE731-3', 'FA7X': 'PW307A', \n",
    "                 'FA900': 'TFE731-3', 'F100': 'TAY 650', 'G200': 'PW306A', 'G400': 'TAY 611-8C', \n",
    "                 'G500': 'PW814GA', 'G650': 'PW815GA', 'LJ31': 'TFE731-2-2B', 'LJ35': 'TFE731-2-2B', \n",
    "                 'LJ40': 'TFE731 SERIES', 'LJ55': 'TFE731-3', 'MD11': 'CF6-80C2 SERIES', 'MD80': 'JT8D SERIES', \n",
    "                 'MD90': 'V2525-D5', 'RJ1H': 'LF507-1F'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fuel_emissions_fulldf(flight_data):        \n",
    "    print(datetime.now())\n",
    "    #first merge: merging flight data with engine types for each flight \n",
    "    dfv1 = flight_data.merge(aircraft_model_names, left_on = 'TailNumber', right_index = True, how = 'left')\n",
    "    dfv1 = dfv1.drop('ENG MFR MDL', axis = 1);\n",
    "    \n",
    "    missing = dfv1[(dfv1['MODEL'].isnull()) & ~(dfv1['AircraftType'].isnull())] #only engine model is missing; aircraft type is not missing\n",
    "    not_missing = dfv1[~(dfv1['AircraftType'].isnull()) & ~(dfv1['MODEL'].isnull())] #both engine model and ac type are not misisng \n",
    "    not_missing['MODEL'] = not_missing['MODEL'].str.strip()\n",
    "    missing.index = missing.index.astype(int); not_missing.index = not_missing.index.astype(int)\n",
    "    \n",
    "    #creating dictionary matching aircraft type to engine models\n",
    "    ac_type_model = not_missing[['AircraftType', 'MODEL']].drop_duplicates()\n",
    "    ac_type_model = ac_type_model.dropna()\n",
    "    drop_indices = ac_type_model[(ac_type_model['AircraftType'].str.len() != 4) & (ac_type_model['AircraftType'].str.len() != 3)].index\n",
    "    ac_type_model = ac_type_model.drop(drop_indices)\n",
    "    ac_types = [i[0] for i in ac_type_model.groupby('AircraftType')]\n",
    "    \n",
    "    #for loop below runs through present aircraft types and determines most likely engine pairing based on\n",
    "    #density based clustering algorithm using levenshtein distance between strings\n",
    "    ac_type_engine_dict = {}\n",
    "    for aa in ac_types:\n",
    "        matching_engines = list(ac_type_model[ac_type_model['AircraftType'] == aa]['MODEL'])\n",
    "        try:\n",
    "            #defining levenshtein distance for list of strings\n",
    "            def lev_metric(x, y):\n",
    "                i, j = int(x[0]), int(y[0])     # extract indices\n",
    "                return levenshtein(matching_engines[i], matching_engines[j])\n",
    "            X = np.arange(len(matching_engines)).reshape(-1, 1)\n",
    "            grouping = list(dbscan(X, metric=lev_metric, eps=9, min_samples=2, algorithm='brute')[1])\n",
    "            mode = matching_engines[grouping.index(st.mode(grouping))]\n",
    "            approx_ac_type = re.search(r'.*(?=-)|.*(?=\\s)', mode).group(0) + ' SERIES'\n",
    "        except:\n",
    "            mode = sorted(matching_engines)[0]\n",
    "            try:\n",
    "                approx_ac_type = re.search(r'.*(?=-)|.*(?=\\s)', mode).group(0) + ' SERIES'\n",
    "            except:\n",
    "                approx_ac_type = mode + ' SERIES'\n",
    "        ac_type_engine_dict[aa] = approx_ac_type\n",
    "    \n",
    "    #maps ac type to engine \n",
    "    mapping = missing['AircraftType'].map(ac_type_engine_dict, na_action='ignore')\n",
    "    mapping = mapping.dropna()\n",
    "    dfv1.loc[mapping.index, 'MODEL'] = mapping\n",
    "    dfv1['MODEL'] = dfv1['MODEL'].str.strip()\n",
    "    dfv1.index = dfv1.index.astype(int)\n",
    "    \n",
    "    still_missing = dfv1[dfv1['MODEL'].isnull()]\n",
    "    still_missing_mapping = still_missing['AircraftType'].map(engine_approx, na_action = 'ignore')\n",
    "    still_missing_mapping = still_missing_mapping.dropna()\n",
    "    \n",
    "    dfv1.loc[still_missing.index, 'MODEL'] = still_missing_mapping\n",
    "    dfv1 = dfv1.dropna()\n",
    "    dfv1['MODEL'] = dfv1['MODEL'].str.strip()\n",
    "    dfv1.index = dfv1.index.astype(int)\n",
    "    \n",
    "    print('First merge made and approximations subsituted')\n",
    "    first_loss = str(round(100 * (len(flight_data) - len(dfv1))/len(flight_data), 2))\n",
    "    print('Data lost at 1st merge: ' + first_loss + '%')\n",
    "    \n",
    "    #create approximations of fuel flow for engine models not listed in fuel_flow_df\n",
    "    missing_groups = list(set(dfv1['MODEL']) - set(fuel_flow_emissions.index))\n",
    "    for kk in missing_groups:\n",
    "        if 'SERIES' in kk:\n",
    "            series_name = kk.replace(' SERIES', '')\n",
    "            closest_matches = get_close_matches_icase(series_name, fuel_flow_emissions.index)\n",
    "            approx_fuel_flow = fuel_flow_emissions.loc[closest_matches].mean(axis = 0) #returns a pd.Series \n",
    "            new_row = pd.concat([pd.Series([kk]), approx_fuel_flow])\n",
    "            fuel_flow_emissions.loc[kk] = new_row\n",
    "        else:\n",
    "            closest_matches = get_close_matches_icase(kk, fuel_flow_emissions.index)\n",
    "            approx_fuel_flow = fuel_flow_emissions.loc[closest_matches].mean(axis = 0) #returns a pd.Series \n",
    "            new_row = pd.concat([pd.Series([kk]), approx_fuel_flow])\n",
    "            fuel_flow_emissions.loc[kk] = new_row\n",
    "    print('Approximations for missing engine models made...')\n",
    "\n",
    "    #second merge: merging dfv1 with fuel flow emissions by engine model\n",
    "    dfv2 = dfv1.merge(fuel_flow_emissions, on = 'MODEL', how = 'left')\n",
    "    dfv2 = dfv2.dropna()\n",
    "    print('Second merge made...')\n",
    "    second_loss = str(round((len(dfv1) - len(dfv2))/len(flight_data),2)*100)\n",
    "    print('Data lost at 2nd merge: ' + second_loss + '%')\n",
    "    \n",
    "    month = dfv2.ScheduledDepartureDate.str[0:2].astype(int)\n",
    "    time = dfv2['ActualWheelsOff'].str[0:2].astype(int)\n",
    "    temp_array = dfv2[['FlightNumber']] * 0\n",
    "    temp_array = temp_array.rename(columns = {'FlightNumber': 'Temperature'})\n",
    "    \n",
    "    #data averaged from https://www.usclimatedata.com/climate/winters/california/united-states/usca1252\n",
    "    #low temperature == AM, high temperature == PM\n",
    "    #spring, PM\n",
    "    temp_array.loc[dfv2[((month == 3) | (month == 4) | (month == 5)) & ((time < 6) | (time >= 18))].index] = sp_l + 459.67\n",
    "    #spring, AM\n",
    "    temp_array.loc[dfv2[((month == 3) | (month == 4) | (month == 5)) & ((time >= 6) | (time < 18))].index] = sp_h + 459.67\n",
    "    #summer, PM\n",
    "    temp_array.loc[dfv2[((month == 6) | (month == 7) | (month == 8)) & ((time < 6) | (time >= 18))].index] = su_l + 459.67\n",
    "    #summer, AM\n",
    "    temp_array.loc[dfv2[((month == 6) | (month == 7) | (month == 8)) & ((time >= 6) | (time < 18))].index] = su_h + 459.67\n",
    "    #fall, PM\n",
    "    temp_array.loc[dfv2[((month == 9) | (month == 10) | (month == 11)) & ((time < 6) | (time >= 18))].index] = fa_l + 459.67\n",
    "    #fal, AM\n",
    "    temp_array.loc[dfv2[((month == 9) | (month == 10) | (month == 11)) & ((time >= 6) | (time < 18))].index] = fa_h + 459.67\n",
    "    #winter, PM\n",
    "    temp_array.loc[dfv2[((month == 12) | (month == 1) | (month == 2)) & ((time < 6) | (time >= 18))].index] = wi_l + 459.67\n",
    "    #winter, AM \n",
    "    temp_array.loc[dfv2[((month == 12) | (month == 1) | (month == 2)) & ((time >= 6) | (time < 18))].index] = wi_h + 459.67\n",
    "    dfv2['Temperature'] = temp_array\n",
    "    dfv2['Pressure'] = [29.92/2.036]*len(dfv2) #standard pressure at sea level (29.92 in Hg)\n",
    "    print('Temperature and pressure coefficients successfully calculated!...')\n",
    "    \n",
    "    #begin final emission calculations\n",
    "    temp_pres_coeff = ((dfv2['Temperature'] / 518.67)**3.5) / (dfv2['Pressure'] / 14.696) #temp and pressure coefficient \n",
    "    print(np.mean(temp_pres_coeff))\n",
    "    \n",
    "    approach_landing = 0.5\n",
    "    CCD_time = dfv2['ActualAirborneTime'] - 0.7 - 2.2 - 4 #CCD_time = total_airborne_time - takeoff - climbout - approach\n",
    "    total_taxi_idle = dfv2['TaxiInTime'] - approach_landing + dfv2['TaxiOutTime'] #this taxi data includes any delays/idle on tarmac, 0.5 mins subtracted for land on runway (counted as approach for ICAO)\n",
    "    \n",
    "    taxi_in_time = dfv2['TaxiInTime'] - approach_landing\n",
    "    taxi_out_time = dfv2['TaxiOutTime']\n",
    "    \n",
    "    dfv2['Total Taxi/Idle (min)'] = total_taxi_idle\n",
    "    dfv2['Cruise Time (min)'] = CCD_time\n",
    "    \n",
    "    #Fuel Consumption (fc) Calculations \n",
    "    fc_to = temp_pres_coeff * dfv2['Fuel Flow T/O (kg/sec)'] * 0.7 * 60 #get units in seconds, not minutes\n",
    "    fc_co = temp_pres_coeff * dfv2['Fuel Flow C/O (kg/sec)'] * 2.2 * 60\n",
    "    fc_ccd = dfv2['Fuel Flow CCD (kg/sec)'] * CCD_time * 60\n",
    "    fc_app = temp_pres_coeff * dfv2['Fuel Flow App (kg/sec)'] * 4 * 60\n",
    "    fc_idle = temp_pres_coeff * dfv2['Fuel Flow Idle (kg/sec)'] * total_taxi_idle * 60\n",
    "    \n",
    "    fc_taxi_in = temp_pres_coeff * dfv2['Fuel Flow Idle (kg/sec)'] * taxi_in_time * 60 #arriving airports\n",
    "    fc_taxi_out = temp_pres_coeff * dfv2['Fuel Flow Idle (kg/sec)'] * taxi_out_time * 60 #departing airports\n",
    "    \n",
    "    if 'Frac in CA' in list(dfv2): #if the flights are out-of-CA\n",
    "        #na = non-adjusted, i.e., includes fuel flow and LTO durations for out of CA airports for T/O, C/O and approach\n",
    "        fc_to_na = fc_to.copy(); fc_to *= dfv2['From CA']\n",
    "        print(fc_to_na)\n",
    "        fc_co_na = fc_co.copy(); fc_co *= dfv2['From CA']\n",
    "        fc_ccd *= dfv2['Frac in CA']\n",
    "        fc_app_na = fc_app.copy(); fc_app *= (1 - dfv2['From CA'])\n",
    "        #for taxi/idle:\n",
    "        taxi_time_adjusted = (dfv2['TaxiOutTime'] * dfv2['From CA']) + (dfv2['TaxiInTime'] * (1 - dfv2['From CA']))\n",
    "        fc_idle = temp_pres_coeff * taxi_time_adjusted * dfv2['Fuel Flow Idle (kg/sec)'] * 60 #switch to seconds\n",
    "        \n",
    "        #also, export the distance flown within CA for calculations later:\n",
    "        dfv2['Distance (NM)'] = dfv2['Frac in CA'] * dfv2['Distance (NM)']\n",
    "                \n",
    "    fuel_consumption = fc_ccd + fc_to + fc_co + fc_app + fc_idle #total fuel consumption\n",
    "    dfv2['Fuel Consumption (kg)'] = dfv2['No. Engines'] * fuel_consumption;\n",
    "    #note: cruising EI data already given with pressure/temp coeff multiplied, so no need to multiply\n",
    "    #by temp and pressure coefficient\n",
    "        \n",
    "    #PM Calculation (if the pollutant is SN == 'Smoke Number', the emissions indices are not directly given, \n",
    "    #but calculated using the following equation (PM_ei):\n",
    "    PM_ei = lambda SN: (6.32e-2 * SN + 8.17e-3 * SN**2 + 3.01e-4 * SN**3 + 4.05e-6 * SN**4) / 1.225 #divide by ambient air density\n",
    "    PM_ei_to = (PM_ei(dfv2['SN EI T/O']) * 50) / 1000 #divide by 1000 to convert mg to grams, so that\n",
    "    #PM EI is in g/kg fuel burned\n",
    "    PM_ei_co = (PM_ei(dfv2['SN EI C/O']) * 60) / 1000\n",
    "    PM_ei_ccd = dfv2['PM EI CCD (g/kg)'] #PM data given directly in EEA Master Emissions Data, not need to use \n",
    "    #the above lambda function to calculate it\n",
    "    PM_ei_app = (PM_ei(dfv2['SN EI App']) * 100) / 1000\n",
    "    PM_ei_idle = (PM_ei(dfv2['SN EI Idle']) * 120) / 1000\n",
    "    emissions_PM_total = PM_ei_to * fc_to + PM_ei_co * fc_co + PM_ei_ccd * fc_ccd + PM_ei_app * fc_app + PM_ei_idle * fc_idle\n",
    "    if 'Frac in CA' in list(dfv2):\n",
    "        #PM at departing airport only includes fuel flow/times from takeoff, climbout, and taxi/idle at departure airport\n",
    "        dep_airport_PM = PM_ei_to * fc_to_na + PM_ei_co * fc_co_na + PM_ei_idle * fc_taxi_out\n",
    "        #PM at arriving airport incl. emissions from approach and taxi/idle at arriving airport\n",
    "        arr_airport_PM = PM_ei_app * fc_app_na + PM_ei_idle * fc_taxi_in\n",
    "        dfv2['PM Dep Airport (kg)'] = (dep_airport_PM * dfv2['No. Engines']) / 1000\n",
    "        dfv2['PM Arr Airport (kg)'] = (arr_airport_PM * dfv2['No. Engines']) / 1000\n",
    "    else:\n",
    "        #PM at departing airport only includes emissions from takeoff, climbout, and taxi/idle at departure airport\n",
    "        dep_airport_PM = PM_ei_to * fc_to + PM_ei_co * fc_co + PM_ei_idle * fc_taxi_out\n",
    "        #PM at arriving airport incl. emissions from approach and taxi/idle at arriving airport\n",
    "        arr_airport_PM = PM_ei_app * fc_app + PM_ei_idle * fc_taxi_in\n",
    "        dfv2['PM Dep Airport (kg)'] = (dep_airport_PM * dfv2['No. Engines']) / 1000\n",
    "        dfv2['PM Arr Airport (kg)'] = (arr_airport_PM * dfv2['No. Engines']) / 1000           \n",
    "            \n",
    "    dfv2['PM (kg)'] = (emissions_PM_total * dfv2['No. Engines']) / 1000\n",
    "    \n",
    "    #CO2 calculations:\n",
    "    CO2_emissions = (fuel_consumption - fc_ccd ) * 3.16 + fc_ccd * dfv2['CO2 EI CCD (kg/kg)']\n",
    "    dfv2['CO2 (kg)'] = CO2_emissions * dfv2['No. Engines']\n",
    "    \n",
    "    #HC, CO, NOx calclations:\n",
    "    pollutants = ['HC', 'CO', 'NOx']\n",
    "    for pollutant in pollutants:\n",
    "        ei_columns = [name for name in list(dfv2) if pollutant in name]\n",
    "        ei_columns = sorted(ei_columns) #when in alphabetical order: App, C/O, CCD, Idle, T/O\n",
    "        to_emissions = dfv2[ei_columns[4]] * fc_to\n",
    "        co_emissions = dfv2[ei_columns[1]] * fc_co\n",
    "        ccd_emissions = dfv2[ei_columns[2]] * fc_ccd\n",
    "        app_emissions = dfv2[ei_columns[0]] * fc_app\n",
    "        idle_emissions = dfv2[ei_columns[3]] * fc_idle\n",
    "        emissions_total = to_emissions + co_emissions + ccd_emissions + app_emissions + idle_emissions\n",
    "        if (pollutant == 'NOx') & ('Frac in CA' in list(dfv2)):\n",
    "            dep_airport_nox = dfv2[ei_columns[4]] * fc_to_na + dfv2[ei_columns[1]] * fc_co_na + dfv2[ei_columns[3]] * fc_taxi_out\n",
    "            arr_airport_nox = dfv2[ei_columns[0]] * fc_app_na + dfv2[ei_columns[3]] * fc_taxi_in\n",
    "            dfv2['NOx Dep Airport (kg)'] = (dep_airport_nox * dfv2['No. Engines']) / 1000\n",
    "            dfv2['NOx Arr Airport (kg)'] = (arr_airport_nox * dfv2['No. Engines']) / 1000\n",
    "        elif pollutant == 'NOx':\n",
    "            dep_airport_nox = dfv2[ei_columns[4]] * fc_to + dfv2[ei_columns[1]] * fc_co + dfv2[ei_columns[3]] * fc_taxi_out\n",
    "            arr_airport_nox = dfv2[ei_columns[0]] * fc_app + dfv2[ei_columns[3]] * fc_taxi_in\n",
    "            dfv2['NOx Dep Airport (kg)'] = (dep_airport_nox * dfv2['No. Engines']) / 1000\n",
    "            dfv2['NOx Arr Airport (kg)'] = (arr_airport_nox * dfv2['No. Engines']) / 1000\n",
    "        column_name = pollutant + ' (kg)'\n",
    "        dfv2[column_name] = (emissions_total * dfv2['No. Engines']) / 1000\n",
    "        \n",
    "    fuel_emissions_final = dfv2[['OD Pair Name', 'AircraftType', 'Carrier', 'FlightNumber', 'Departure', 'Arrival', \n",
    "                                     'ScheduledDepartureDate', 'ActualWheelsOff', 'ActualWheelsOn', 'Distance (NM)',\n",
    "                                     'Cruise Time (min)', 'Total Taxi/Idle (min)', 'Fuel Consumption (kg)', \n",
    "                                     'CO2 (kg)', 'HC (kg)', 'CO (kg)', 'NOx (kg)', 'NOx Dep Airport (kg)', 'NOx Arr Airport (kg)', \n",
    "                                     'PM (kg)', 'PM Dep Airport (kg)', 'PM Arr Airport (kg)']]\n",
    "                                 \n",
    "    fuel_emissions_final['FlightNumber'] = fuel_emissions_final['FlightNumber'].astype(int)\n",
    "    length_orig = len(fuel_emissions_final)\n",
    "    fuel_emissions_final = fuel_emissions_final.dropna()\n",
    "    #fuel_emissions_final = fuel_emissions_final.drop_duplicates()\n",
    "    length_fin = len(fuel_emissions_final)\n",
    "    final_data_dropoff = round(100 * (length_orig - length_fin)/len(flight_data), 2)\n",
    "    print('Data lost after dropping NaN: ' + str(final_data_dropoff) + '%')\n",
    "    return fuel_emissions_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-20 18:11:33.142422\n",
      "First merge made and approximations subsituted\n",
      "Data lost at 1st merge: 9.98%\n",
      "Approximations for missing engine models made...\n",
      "Second merge made...\n",
      "Data lost at 2nd merge: 5.0%\n",
      "Temperature and pressure coefficients successfully calculated!...\n",
      "1.0707657199813971\n",
      "Data lost after dropping NaN: 0.0%\n"
     ]
    }
   ],
   "source": [
    "x = calculate_fuel_emissions_fulldf(intra_CA)\n",
    "#x.to_csv(all_US_CA_airport_emissions, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OD Pair Name</th>\n",
       "      <th>AircraftType</th>\n",
       "      <th>Carrier</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>ScheduledDepartureDate</th>\n",
       "      <th>ActualWheelsOff</th>\n",
       "      <th>ActualWheelsOn</th>\n",
       "      <th>Distance (NM)</th>\n",
       "      <th>...</th>\n",
       "      <th>Fuel Consumption (kg)</th>\n",
       "      <th>CO2 (kg)</th>\n",
       "      <th>HC (kg)</th>\n",
       "      <th>CO (kg)</th>\n",
       "      <th>NOx (kg)</th>\n",
       "      <th>NOx Dep Airport (kg)</th>\n",
       "      <th>NOx Arr Airport (kg)</th>\n",
       "      <th>PM (kg)</th>\n",
       "      <th>PM Dep Airport (kg)</th>\n",
       "      <th>PM Arr Airport (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACVONT</td>\n",
       "      <td>BD700</td>\n",
       "      <td>EJA</td>\n",
       "      <td>100</td>\n",
       "      <td>ONT</td>\n",
       "      <td>ACV</td>\n",
       "      <td>07/20/2019</td>\n",
       "      <td>13:47</td>\n",
       "      <td>15:00</td>\n",
       "      <td>517.909918</td>\n",
       "      <td>...</td>\n",
       "      <td>4759.683037</td>\n",
       "      <td>14998.223390</td>\n",
       "      <td>0.491617</td>\n",
       "      <td>18.039929</td>\n",
       "      <td>58.428146</td>\n",
       "      <td>6.987790</td>\n",
       "      <td>1.700206</td>\n",
       "      <td>1.347576</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACVVNY</td>\n",
       "      <td>BD700</td>\n",
       "      <td>EJA</td>\n",
       "      <td>112</td>\n",
       "      <td>VNY</td>\n",
       "      <td>ACV</td>\n",
       "      <td>07/20/2019</td>\n",
       "      <td>17:44</td>\n",
       "      <td>18:56</td>\n",
       "      <td>485.869997</td>\n",
       "      <td>...</td>\n",
       "      <td>4790.283844</td>\n",
       "      <td>15095.377259</td>\n",
       "      <td>0.512702</td>\n",
       "      <td>19.565433</td>\n",
       "      <td>58.653735</td>\n",
       "      <td>7.313368</td>\n",
       "      <td>1.765321</td>\n",
       "      <td>1.342151</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.001034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACVSNA</td>\n",
       "      <td>C680</td>\n",
       "      <td>EJA</td>\n",
       "      <td>361</td>\n",
       "      <td>SNA</td>\n",
       "      <td>ACV</td>\n",
       "      <td>12/25/2019</td>\n",
       "      <td>17:58</td>\n",
       "      <td>19:26</td>\n",
       "      <td>529.471248</td>\n",
       "      <td>...</td>\n",
       "      <td>2679.520867</td>\n",
       "      <td>8442.987150</td>\n",
       "      <td>0.536423</td>\n",
       "      <td>18.376337</td>\n",
       "      <td>40.369658</td>\n",
       "      <td>2.124281</td>\n",
       "      <td>0.683520</td>\n",
       "      <td>0.220030</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACVLAX</td>\n",
       "      <td>C680</td>\n",
       "      <td>EJA</td>\n",
       "      <td>506</td>\n",
       "      <td>LAX</td>\n",
       "      <td>ACV</td>\n",
       "      <td>07/22/2019</td>\n",
       "      <td>14:53</td>\n",
       "      <td>16:08</td>\n",
       "      <td>501.659190</td>\n",
       "      <td>...</td>\n",
       "      <td>2327.723268</td>\n",
       "      <td>7335.037266</td>\n",
       "      <td>0.522760</td>\n",
       "      <td>16.176010</td>\n",
       "      <td>35.226031</td>\n",
       "      <td>2.362673</td>\n",
       "      <td>0.704274</td>\n",
       "      <td>0.184248</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACVOAK</td>\n",
       "      <td>C750</td>\n",
       "      <td>EJA</td>\n",
       "      <td>990</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ACV</td>\n",
       "      <td>05/16/2019</td>\n",
       "      <td>18:00</td>\n",
       "      <td>18:45</td>\n",
       "      <td>214.085139</td>\n",
       "      <td>...</td>\n",
       "      <td>1566.069451</td>\n",
       "      <td>4935.566411</td>\n",
       "      <td>0.864874</td>\n",
       "      <td>4.897994</td>\n",
       "      <td>19.529446</td>\n",
       "      <td>2.072182</td>\n",
       "      <td>0.483379</td>\n",
       "      <td>0.090232</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583808</th>\n",
       "      <td>OAKSTS</td>\n",
       "      <td>C750</td>\n",
       "      <td>XOJ</td>\n",
       "      <td>774</td>\n",
       "      <td>OAK</td>\n",
       "      <td>STS</td>\n",
       "      <td>06/03/2019</td>\n",
       "      <td>09:34</td>\n",
       "      <td>09:49</td>\n",
       "      <td>54.905301</td>\n",
       "      <td>...</td>\n",
       "      <td>540.205124</td>\n",
       "      <td>1704.132495</td>\n",
       "      <td>0.562635</td>\n",
       "      <td>3.226157</td>\n",
       "      <td>6.068915</td>\n",
       "      <td>2.062974</td>\n",
       "      <td>0.451651</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583809</th>\n",
       "      <td>OAKSJC</td>\n",
       "      <td>C750</td>\n",
       "      <td>XOJ</td>\n",
       "      <td>782</td>\n",
       "      <td>OAK</td>\n",
       "      <td>SJC</td>\n",
       "      <td>06/16/2019</td>\n",
       "      <td>14:29</td>\n",
       "      <td>14:47</td>\n",
       "      <td>25.617374</td>\n",
       "      <td>...</td>\n",
       "      <td>577.854480</td>\n",
       "      <td>1822.528227</td>\n",
       "      <td>0.455912</td>\n",
       "      <td>2.649011</td>\n",
       "      <td>6.692062</td>\n",
       "      <td>1.989041</td>\n",
       "      <td>0.451651</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583810</th>\n",
       "      <td>OAKSFO</td>\n",
       "      <td>C750</td>\n",
       "      <td>XOJ</td>\n",
       "      <td>789</td>\n",
       "      <td>OAK</td>\n",
       "      <td>SFO</td>\n",
       "      <td>06/05/2019</td>\n",
       "      <td>12:56</td>\n",
       "      <td>13:08</td>\n",
       "      <td>9.560567</td>\n",
       "      <td>...</td>\n",
       "      <td>429.995705</td>\n",
       "      <td>1357.198185</td>\n",
       "      <td>0.635683</td>\n",
       "      <td>3.622388</td>\n",
       "      <td>4.502377</td>\n",
       "      <td>2.026008</td>\n",
       "      <td>0.544067</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583811</th>\n",
       "      <td>OAKSNA</td>\n",
       "      <td>C750</td>\n",
       "      <td>XOJ</td>\n",
       "      <td>792</td>\n",
       "      <td>OAK</td>\n",
       "      <td>SNA</td>\n",
       "      <td>06/16/2019</td>\n",
       "      <td>17:13</td>\n",
       "      <td>18:15</td>\n",
       "      <td>322.400272</td>\n",
       "      <td>...</td>\n",
       "      <td>2092.240244</td>\n",
       "      <td>6594.425395</td>\n",
       "      <td>0.828765</td>\n",
       "      <td>4.685890</td>\n",
       "      <td>27.147772</td>\n",
       "      <td>2.192356</td>\n",
       "      <td>0.433168</td>\n",
       "      <td>0.121488</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583812</th>\n",
       "      <td>OAKSJC</td>\n",
       "      <td>C750</td>\n",
       "      <td>XOJ</td>\n",
       "      <td>793</td>\n",
       "      <td>OAK</td>\n",
       "      <td>SJC</td>\n",
       "      <td>06/22/2019</td>\n",
       "      <td>16:20</td>\n",
       "      <td>16:38</td>\n",
       "      <td>25.617374</td>\n",
       "      <td>...</td>\n",
       "      <td>589.079069</td>\n",
       "      <td>1857.997930</td>\n",
       "      <td>0.514119</td>\n",
       "      <td>2.978715</td>\n",
       "      <td>6.729029</td>\n",
       "      <td>2.044491</td>\n",
       "      <td>0.433168</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550081 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       OD Pair Name AircraftType Carrier  FlightNumber Departure Arrival  \\\n",
       "0            ACVONT        BD700     EJA           100       ONT     ACV   \n",
       "1            ACVVNY        BD700     EJA           112       VNY     ACV   \n",
       "2            ACVSNA         C680     EJA           361       SNA     ACV   \n",
       "3            ACVLAX         C680     EJA           506       LAX     ACV   \n",
       "4            ACVOAK         C750     EJA           990       OAK     ACV   \n",
       "...             ...          ...     ...           ...       ...     ...   \n",
       "583808       OAKSTS         C750     XOJ           774       OAK     STS   \n",
       "583809       OAKSJC         C750     XOJ           782       OAK     SJC   \n",
       "583810       OAKSFO         C750     XOJ           789       OAK     SFO   \n",
       "583811       OAKSNA         C750     XOJ           792       OAK     SNA   \n",
       "583812       OAKSJC         C750     XOJ           793       OAK     SJC   \n",
       "\n",
       "       ScheduledDepartureDate ActualWheelsOff ActualWheelsOn  Distance (NM)  \\\n",
       "0                  07/20/2019           13:47          15:00     517.909918   \n",
       "1                  07/20/2019           17:44          18:56     485.869997   \n",
       "2                  12/25/2019           17:58          19:26     529.471248   \n",
       "3                  07/22/2019           14:53          16:08     501.659190   \n",
       "4                  05/16/2019           18:00          18:45     214.085139   \n",
       "...                       ...             ...            ...            ...   \n",
       "583808             06/03/2019           09:34          09:49      54.905301   \n",
       "583809             06/16/2019           14:29          14:47      25.617374   \n",
       "583810             06/05/2019           12:56          13:08       9.560567   \n",
       "583811             06/16/2019           17:13          18:15     322.400272   \n",
       "583812             06/22/2019           16:20          16:38      25.617374   \n",
       "\n",
       "        ...  Fuel Consumption (kg)      CO2 (kg)   HC (kg)    CO (kg)  \\\n",
       "0       ...            4759.683037  14998.223390  0.491617  18.039929   \n",
       "1       ...            4790.283844  15095.377259  0.512702  19.565433   \n",
       "2       ...            2679.520867   8442.987150  0.536423  18.376337   \n",
       "3       ...            2327.723268   7335.037266  0.522760  16.176010   \n",
       "4       ...            1566.069451   4935.566411  0.864874   4.897994   \n",
       "...     ...                    ...           ...       ...        ...   \n",
       "583808  ...             540.205124   1704.132495  0.562635   3.226157   \n",
       "583809  ...             577.854480   1822.528227  0.455912   2.649011   \n",
       "583810  ...             429.995705   1357.198185  0.635683   3.622388   \n",
       "583811  ...            2092.240244   6594.425395  0.828765   4.685890   \n",
       "583812  ...             589.079069   1857.997930  0.514119   2.978715   \n",
       "\n",
       "         NOx (kg)  NOx Dep Airport (kg)  NOx Arr Airport (kg)   PM (kg)  \\\n",
       "0       58.428146              6.987790              1.700206  1.347576   \n",
       "1       58.653735              7.313368              1.765321  1.342151   \n",
       "2       40.369658              2.124281              0.683520  0.220030   \n",
       "3       35.226031              2.362673              0.704274  0.184248   \n",
       "4       19.529446              2.072182              0.483379  0.090232   \n",
       "...           ...                   ...                   ...       ...   \n",
       "583808   6.068915              2.062974              0.451651  0.010388   \n",
       "583809   6.692062              1.989041              0.451651  0.009912   \n",
       "583810   4.502377              2.026008              0.544067  0.003907   \n",
       "583811  27.147772              2.192356              0.433168  0.121488   \n",
       "583812   6.729029              2.044491              0.433168  0.009913   \n",
       "\n",
       "        PM Dep Airport (kg)  PM Arr Airport (kg)  \n",
       "0                  0.005411             0.000992  \n",
       "1                  0.005625             0.001034  \n",
       "2                  0.000507             0.000036  \n",
       "3                  0.000566             0.000025  \n",
       "4                  0.000060             0.000003  \n",
       "...                     ...                  ...  \n",
       "583808             0.000061             0.000003  \n",
       "583809             0.000060             0.000003  \n",
       "583810             0.000061             0.000004  \n",
       "583811             0.000063             0.000003  \n",
       "583812             0.000061             0.000003  \n",
       "\n",
       "[550081 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x.to_csv('Results/intra-CA-emissions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-20 18:18:23.377882\n",
      "First merge made and approximations subsituted\n",
      "Data lost at 1st merge: 1.63%\n",
      "Approximations for missing engine models made...\n",
      "Second merge made...\n",
      "Data lost at 2nd merge: 4.0%\n",
      "Temperature and pressure coefficients successfully calculated!...\n",
      "1.0711754486444105\n",
      "0          33.440495\n",
      "1          33.440495\n",
      "4          17.233617\n",
      "5          33.440495\n",
      "6          41.240248\n",
      "             ...    \n",
      "1315801    18.372584\n",
      "1315802    18.372584\n",
      "1315804    40.593856\n",
      "1315806    13.514418\n",
      "1315807    32.916355\n",
      "Length: 1260158, dtype: float64\n",
      "Data lost after dropping NaN: 0.0%\n"
     ]
    }
   ],
   "source": [
    "z = calculate_fuel_emissions_fulldf(out_of_CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OD Pair Name</th>\n",
       "      <th>AircraftType</th>\n",
       "      <th>Carrier</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>ScheduledDepartureDate</th>\n",
       "      <th>ActualWheelsOff</th>\n",
       "      <th>ActualWheelsOn</th>\n",
       "      <th>Distance (NM)</th>\n",
       "      <th>...</th>\n",
       "      <th>Fuel Consumption (kg)</th>\n",
       "      <th>CO2 (kg)</th>\n",
       "      <th>HC (kg)</th>\n",
       "      <th>CO (kg)</th>\n",
       "      <th>NOx (kg)</th>\n",
       "      <th>NOx Dep Airport (kg)</th>\n",
       "      <th>NOx Arr Airport (kg)</th>\n",
       "      <th>PM (kg)</th>\n",
       "      <th>PM Dep Airport (kg)</th>\n",
       "      <th>PM Arr Airport (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEBUR</td>\n",
       "      <td>G400</td>\n",
       "      <td>EJM</td>\n",
       "      <td>457</td>\n",
       "      <td>ABE</td>\n",
       "      <td>BUR</td>\n",
       "      <td>10/02/2019</td>\n",
       "      <td>09:51</td>\n",
       "      <td>12:09</td>\n",
       "      <td>182.427449</td>\n",
       "      <td>...</td>\n",
       "      <td>1156.068054</td>\n",
       "      <td>3643.038884</td>\n",
       "      <td>0.119426</td>\n",
       "      <td>7.281864</td>\n",
       "      <td>7.173169</td>\n",
       "      <td>4.221434</td>\n",
       "      <td>0.699134</td>\n",
       "      <td>0.133051</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEBUR</td>\n",
       "      <td>G400</td>\n",
       "      <td>EJM</td>\n",
       "      <td>457</td>\n",
       "      <td>BUR</td>\n",
       "      <td>ABE</td>\n",
       "      <td>10/05/2019</td>\n",
       "      <td>09:27</td>\n",
       "      <td>16:48</td>\n",
       "      <td>182.427449</td>\n",
       "      <td>...</td>\n",
       "      <td>1187.049529</td>\n",
       "      <td>3742.797502</td>\n",
       "      <td>0.200798</td>\n",
       "      <td>8.433952</td>\n",
       "      <td>9.494777</td>\n",
       "      <td>4.221434</td>\n",
       "      <td>0.770210</td>\n",
       "      <td>0.111924</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABELAX</td>\n",
       "      <td>CL600</td>\n",
       "      <td>DCM</td>\n",
       "      <td>2877</td>\n",
       "      <td>ABE</td>\n",
       "      <td>LAX</td>\n",
       "      <td>01/14/2019</td>\n",
       "      <td>07:43</td>\n",
       "      <td>10:12</td>\n",
       "      <td>192.072882</td>\n",
       "      <td>...</td>\n",
       "      <td>1017.128034</td>\n",
       "      <td>3205.240799</td>\n",
       "      <td>0.430437</td>\n",
       "      <td>3.622187</td>\n",
       "      <td>6.829657</td>\n",
       "      <td>1.923185</td>\n",
       "      <td>0.628877</td>\n",
       "      <td>0.172889</td>\n",
       "      <td>0.022948</td>\n",
       "      <td>0.003086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABELAX</td>\n",
       "      <td>G400</td>\n",
       "      <td>EJM</td>\n",
       "      <td>457</td>\n",
       "      <td>ABE</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10/06/2019</td>\n",
       "      <td>08:19</td>\n",
       "      <td>10:51</td>\n",
       "      <td>192.072882</td>\n",
       "      <td>...</td>\n",
       "      <td>1373.653744</td>\n",
       "      <td>4329.639683</td>\n",
       "      <td>0.280892</td>\n",
       "      <td>11.065888</td>\n",
       "      <td>8.107978</td>\n",
       "      <td>4.221434</td>\n",
       "      <td>1.018976</td>\n",
       "      <td>0.145904</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABEOAK</td>\n",
       "      <td>BD700</td>\n",
       "      <td>EJA</td>\n",
       "      <td>100</td>\n",
       "      <td>ABE</td>\n",
       "      <td>OAK</td>\n",
       "      <td>09/22/2019</td>\n",
       "      <td>15:53</td>\n",
       "      <td>18:14</td>\n",
       "      <td>171.470403</td>\n",
       "      <td>...</td>\n",
       "      <td>1467.087334</td>\n",
       "      <td>4623.388699</td>\n",
       "      <td>0.112726</td>\n",
       "      <td>5.889521</td>\n",
       "      <td>14.407340</td>\n",
       "      <td>7.019207</td>\n",
       "      <td>1.709537</td>\n",
       "      <td>0.759897</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315801</th>\n",
       "      <td>VNYYIP</td>\n",
       "      <td>CL600</td>\n",
       "      <td>WWI</td>\n",
       "      <td>84</td>\n",
       "      <td>YIP</td>\n",
       "      <td>VNY</td>\n",
       "      <td>09/28/2019</td>\n",
       "      <td>17:22</td>\n",
       "      <td>18:55</td>\n",
       "      <td>182.088273</td>\n",
       "      <td>...</td>\n",
       "      <td>949.873515</td>\n",
       "      <td>2993.019369</td>\n",
       "      <td>0.290413</td>\n",
       "      <td>2.219662</td>\n",
       "      <td>6.518653</td>\n",
       "      <td>1.662014</td>\n",
       "      <td>0.524837</td>\n",
       "      <td>0.161901</td>\n",
       "      <td>0.021615</td>\n",
       "      <td>0.002221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315802</th>\n",
       "      <td>VNYYIP</td>\n",
       "      <td>CL600</td>\n",
       "      <td>WWI</td>\n",
       "      <td>93</td>\n",
       "      <td>YIP</td>\n",
       "      <td>VNY</td>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>19:05</td>\n",
       "      <td>20:38</td>\n",
       "      <td>182.088273</td>\n",
       "      <td>...</td>\n",
       "      <td>949.873515</td>\n",
       "      <td>2993.019369</td>\n",
       "      <td>0.290413</td>\n",
       "      <td>2.219662</td>\n",
       "      <td>6.518653</td>\n",
       "      <td>1.686281</td>\n",
       "      <td>0.524837</td>\n",
       "      <td>0.161901</td>\n",
       "      <td>0.021793</td>\n",
       "      <td>0.002221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315804</th>\n",
       "      <td>VNYYKM</td>\n",
       "      <td>BD700</td>\n",
       "      <td>LXJ</td>\n",
       "      <td>90</td>\n",
       "      <td>VNY</td>\n",
       "      <td>YKM</td>\n",
       "      <td>03/16/2019</td>\n",
       "      <td>12:12</td>\n",
       "      <td>14:00</td>\n",
       "      <td>238.748500</td>\n",
       "      <td>...</td>\n",
       "      <td>2347.126809</td>\n",
       "      <td>7397.883874</td>\n",
       "      <td>0.218079</td>\n",
       "      <td>9.424227</td>\n",
       "      <td>28.090365</td>\n",
       "      <td>6.971259</td>\n",
       "      <td>1.558603</td>\n",
       "      <td>0.557446</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315806</th>\n",
       "      <td>VNYYUM</td>\n",
       "      <td>C680</td>\n",
       "      <td>EJA</td>\n",
       "      <td>551</td>\n",
       "      <td>VNY</td>\n",
       "      <td>YUM</td>\n",
       "      <td>01/21/2019</td>\n",
       "      <td>18:22</td>\n",
       "      <td>20:07</td>\n",
       "      <td>207.796524</td>\n",
       "      <td>...</td>\n",
       "      <td>1352.486443</td>\n",
       "      <td>4262.246639</td>\n",
       "      <td>0.499617</td>\n",
       "      <td>10.995936</td>\n",
       "      <td>21.647504</td>\n",
       "      <td>2.211843</td>\n",
       "      <td>0.595958</td>\n",
       "      <td>0.088364</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315807</th>\n",
       "      <td>VNYYUM</td>\n",
       "      <td>G400</td>\n",
       "      <td>PEG</td>\n",
       "      <td>26</td>\n",
       "      <td>YUM</td>\n",
       "      <td>VNY</td>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>04:20</td>\n",
       "      <td>04:14</td>\n",
       "      <td>207.796524</td>\n",
       "      <td>...</td>\n",
       "      <td>2243.217446</td>\n",
       "      <td>7067.830157</td>\n",
       "      <td>0.426109</td>\n",
       "      <td>16.047313</td>\n",
       "      <td>18.450096</td>\n",
       "      <td>4.295192</td>\n",
       "      <td>0.793119</td>\n",
       "      <td>0.170607</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260158 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        OD Pair Name AircraftType Carrier  FlightNumber Departure Arrival  \\\n",
       "0             ABEBUR         G400     EJM           457       ABE     BUR   \n",
       "1             ABEBUR         G400     EJM           457       BUR     ABE   \n",
       "4             ABELAX        CL600     DCM          2877       ABE     LAX   \n",
       "5             ABELAX         G400     EJM           457       ABE     LAX   \n",
       "6             ABEOAK        BD700     EJA           100       ABE     OAK   \n",
       "...              ...          ...     ...           ...       ...     ...   \n",
       "1315801       VNYYIP        CL600     WWI            84       YIP     VNY   \n",
       "1315802       VNYYIP        CL600     WWI            93       YIP     VNY   \n",
       "1315804       VNYYKM        BD700     LXJ            90       VNY     YKM   \n",
       "1315806       VNYYUM         C680     EJA           551       VNY     YUM   \n",
       "1315807       VNYYUM         G400     PEG            26       YUM     VNY   \n",
       "\n",
       "        ScheduledDepartureDate ActualWheelsOff ActualWheelsOn  Distance (NM)  \\\n",
       "0                   10/02/2019           09:51          12:09     182.427449   \n",
       "1                   10/05/2019           09:27          16:48     182.427449   \n",
       "4                   01/14/2019           07:43          10:12     192.072882   \n",
       "5                   10/06/2019           08:19          10:51     192.072882   \n",
       "6                   09/22/2019           15:53          18:14     171.470403   \n",
       "...                        ...             ...            ...            ...   \n",
       "1315801             09/28/2019           17:22          18:55     182.088273   \n",
       "1315802             10/01/2019           19:05          20:38     182.088273   \n",
       "1315804             03/16/2019           12:12          14:00     238.748500   \n",
       "1315806             01/21/2019           18:22          20:07     207.796524   \n",
       "1315807             03/08/2019           04:20          04:14     207.796524   \n",
       "\n",
       "         ...  Fuel Consumption (kg)     CO2 (kg)   HC (kg)    CO (kg)  \\\n",
       "0        ...            1156.068054  3643.038884  0.119426   7.281864   \n",
       "1        ...            1187.049529  3742.797502  0.200798   8.433952   \n",
       "4        ...            1017.128034  3205.240799  0.430437   3.622187   \n",
       "5        ...            1373.653744  4329.639683  0.280892  11.065888   \n",
       "6        ...            1467.087334  4623.388699  0.112726   5.889521   \n",
       "...      ...                    ...          ...       ...        ...   \n",
       "1315801  ...             949.873515  2993.019369  0.290413   2.219662   \n",
       "1315802  ...             949.873515  2993.019369  0.290413   2.219662   \n",
       "1315804  ...            2347.126809  7397.883874  0.218079   9.424227   \n",
       "1315806  ...            1352.486443  4262.246639  0.499617  10.995936   \n",
       "1315807  ...            2243.217446  7067.830157  0.426109  16.047313   \n",
       "\n",
       "          NOx (kg)  NOx Dep Airport (kg)  NOx Arr Airport (kg)   PM (kg)  \\\n",
       "0         7.173169              4.221434              0.699134  0.133051   \n",
       "1         9.494777              4.221434              0.770210  0.111924   \n",
       "4         6.829657              1.923185              0.628877  0.172889   \n",
       "5         8.107978              4.221434              1.018976  0.145904   \n",
       "6        14.407340              7.019207              1.709537  0.759897   \n",
       "...            ...                   ...                   ...       ...   \n",
       "1315801   6.518653              1.662014              0.524837  0.161901   \n",
       "1315802   6.518653              1.686281              0.524837  0.161901   \n",
       "1315804  28.090365              6.971259              1.558603  0.557446   \n",
       "1315806  21.647504              2.211843              0.595958  0.088364   \n",
       "1315807  18.450096              4.295192              0.793119  0.170607   \n",
       "\n",
       "         PM Dep Airport (kg)  PM Arr Airport (kg)  \n",
       "0                   0.003454             0.000242  \n",
       "1                   0.003454             0.000271  \n",
       "4                   0.022948             0.003086  \n",
       "5                   0.003454             0.000372  \n",
       "6                   0.005406             0.001002  \n",
       "...                      ...                  ...  \n",
       "1315801             0.021615             0.002221  \n",
       "1315802             0.021793             0.002221  \n",
       "1315804             0.005362             0.000904  \n",
       "1315806             0.000534             0.000010  \n",
       "1315807             0.003457             0.000281  \n",
       "\n",
       "[1260158 rows x 22 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z.to_csv('Results/out-of-CA-emissions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Unused Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating CCD Fuel Flow and Emissions Indices using Lagrange Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takeoff = [100]*len(fuel_flow_emissions)\n",
    "climbout = [85]*len(fuel_flow_emissions)\n",
    "approach = [30]*len(fuel_flow_emissions)\n",
    "taxi_idle = [7]*len(fuel_flow_emissions)\n",
    "fuel_flow_emissions['Takeoff'] = takeoff; fuel_flow_emissions['Climb Out'] = climbout\n",
    "fuel_flow_emissions['Approach'] = approach; fuel_flow_emissions['Taxi/Idle'] = taxi_idle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Fuel Flow T/O (kg/sec)','Fuel Flow Idle (kg/sec)',\n",
    "           'HC EI T/O (kg/sec)','HC EI Idle (kg/sec)',\n",
    "           'CO EI T/O (kg/sec)','CO EI Idle (kg/sec)',\n",
    "           'NOx EI T/O (kg/sec)','NOx EI Idle (kg/sec)',\n",
    "           'SN T/O','SN Idle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_flow_emissions.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = list(fuel_flow_emissions.loc['AE3007A', 'Fuel Flow T/O (kg/sec)': 'Fuel Flow Idle (kg/sec)'])\n",
    "yy = list(fuel_flow_emissions.loc['AE3007A', 'NOx EI T/O (g/kg)': 'NOx EI Idle (g/kg)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "for ww in fuel_flow_emissions.index:\n",
    "    xx = list(fuel_flow_emissions.loc[ww, 'Fuel Flow T/O (kg/sec)': 'Fuel Flow Idle (kg/sec)'])\n",
    "    yy = list(fuel_flow_emissions.loc[ww, 'NOx EI T/O (g/kg)': 'NOx EI Idle (g/kg)'])\n",
    "    plt.scatter(xx,yy)\n",
    "    plt.plot(xx, yy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#parse out columns of interest\n",
    "columns_of_interest = ['Fuel Flow T/O (kg/sec)','Fuel Flow Idle (kg/sec)',\n",
    "           'HC EI T/O (g/kg)','HC EI Idle (g/kg)',\n",
    "           'CO EI T/O (g/kg)','CO EI Idle (g/kg)',\n",
    "           'NOx EI T/O (g/kg)','NOx EI Idle (g/kg)',\n",
    "           'SN EI T/O','SN EI Idle']\n",
    "\n",
    "#for each type of aircraft, estimate fuel flow and EI for each pollutant\n",
    "for ii in range(int(len(columns_of_interest)/2)):\n",
    "    if ii == 0:\n",
    "        new_name = 'Fuel Flow Cruising'\n",
    "    else:\n",
    "        new_name = re.search(r'\\w+(?=\\sEI)', columns_of_interest[2*ii]).group(0) + ' Cruising'\n",
    "    new_list = []\n",
    "    fig = plt.figure(figsize = (15,10))\n",
    "    for jj in fuel_flow_emissions.index:\n",
    "        x = list(fuel_flow_emissions.loc[jj, 'Takeoff':'Taxi/Idle'])\n",
    "        x_new = range(100)\n",
    "        y = list(fuel_flow_emissions.loc[jj, columns_of_interest[2*ii]:columns_of_interest[2*ii + 1]])\n",
    "        f = lagrange(x, y)\n",
    "        plt.plot(x_new, f(x_new), '#42a1f5', zorder = 1) \n",
    "        plt.scatter(x, y, c = '#f54296', zorder = 2)\n",
    "        plt.xlabel('Thrust Setting (%)')\n",
    "        plt.ylabel(new_name + ' EI (g/kg of fuel)')\n",
    "        cruise_addition = f(80)\n",
    "        if cruise_addition < 0:\n",
    "            slope = (y[2] - y[1]) / (x[2] - x[1])\n",
    "            b = y[1] - slope * x[1]\n",
    "            cruise_addition = slope * 80 + b            \n",
    "        new_list.append(cruise_addition)\n",
    "    fuel_flow_emissions[new_name] = new_list\n",
    "    \n",
    "fuel_flow_emissions = fuel_flow_emissions.drop(['Takeoff', 'Climb Out', 'Approach', 'Taxi/Idle'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping Pressure and Temperature from wunderground.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function that takes date and location and returns wunderground URL for that location and date\n",
    "def create_url(date, location):\n",
    "    location_code = 'K' + location\n",
    "    \n",
    "    #get departure date, put departure date in same format as Wunderground\n",
    "    dep_date = datetime.strptime(date, '%m/%d/%Y')\n",
    "    dt = datetime.strftime(dep_date, '%Y-%m-%d')\n",
    "    #lookbehind regex to remove 0-padding from month and date\n",
    "    dt = re.sub('(?<=-)0', '', dt)\n",
    "\n",
    "    url = 'https://www.wunderground.com/history/daily/' + location_code + '/date/' + dt\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function that takes wunderground URL and time of flight, and returns temperature and pressure\n",
    "def scrape_temp_pres_data(url):\n",
    "    #setting up headless webscraper\n",
    "    chrome_options = Options()\n",
    "    chrome_options.headless = True\n",
    "    driver = webdriver.Chrome(options = chrome_options)\n",
    "    driver.get(url)\n",
    "    element = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \".mat-cell.cdk-cell.cdk-column-condition.mat-column-condition.ng-star-inserted\")))\n",
    "    page_contents = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    tables = page_contents.find_all('table')\n",
    "    \n",
    "    #get data of interest (pressure, avg temperature) based on time given in flight data\n",
    "    historical_data = tables[1]\n",
    "    driver.quit()\n",
    "    table_rows = historical_data.findAll('tr')\n",
    "    print(len(table_rows))\n",
    "    scraped_data = pd.DataFrame()\n",
    "    for jj in range(2, len(table_rows)): #starts at second row (1st is header)\n",
    "        table_row = table_rows[jj]\n",
    "        columns = table_row.findAll('td')\n",
    "        output_row = []\n",
    "        for column in columns:\n",
    "            output_row.append(column.text.strip())\n",
    "        scraped_data = scraped_data.append(output_row)\n",
    "    return scraped_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
